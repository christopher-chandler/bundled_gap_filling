{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /Users/christopherchandler/code_repos/christopher-chandler/Python/nlp/rub/bundled_gap_filling/data/language_model/en-70k-0.2-pruned.lm\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "*The ARPA file is missing <unk>.  Substituting log10 probability -100.\n",
      "***************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisierung...\n",
      "Generiere Distraktoren mit Fastsubs...\n",
      "...\n",
      "Unser erster Satz:\n",
      "'During the autumn harvest, families enjoyed picking <pears> from the trees.'\n",
      "Disambiguation level: -7.62167832897076\n",
      "...\n",
      "Jetzt fangen wir an, weitere Sätze zu suchen.\n",
      "...\n",
      "Satz Nr. 2 gefunden!\n",
      "Disambiguation level: -10.466113693152575\n",
      "Satz Nr. 3 gefunden!\n",
      "Disambiguation level: 1000\n",
      "Satz Nr. 4 gefunden!\n",
      "Disambiguation level: 1000\n",
      "...\n",
      "Hier ist die fertige Bundled Gap Filling Aufgabe:\n",
      "\n",
      "'During the autumn harvest, families enjoyed picking <pears> from the trees.'\n",
      "'The fruit bowl on the kitchen table displayed a mix of <pears> in different shapes and colors.'\n",
      "'Sarah baked a delicious pear and almond tart with the ripe <pears> from her garden.'\n",
      "'As they strolled through the farmers' market, Emily and David picked up apples, <pears>, and oranges for their upcoming picnic.'\n"
     ]
    }
   ],
   "source": [
    "# Standard\n",
    "# None\n",
    "\n",
    "# Pip\n",
    "# None\n",
    "\n",
    "# Custom\n",
    "from api_nlp.sentence_generator.bundled_gap_generator import *\n",
    "\n",
    "\n",
    "def main(corpus, target):\n",
    "    # Korpus, aus dem Sätze gezogen werden sollen, und Target festlegen sowie leeres Bundle initiieren\n",
    "    print(\"Initialisierung...\")\n",
    "    bundle = []\n",
    "    # Sätze, die das Target enthalten, als Liste in Liste schreiben\n",
    "    corpus_list = []\n",
    "    for line in corpus:\n",
    "        if target in line:\n",
    "            # Target markieren\n",
    "            line = line.replace(target, \"<\" + target + \">\")\n",
    "            list = line.split()\n",
    "            # ... und als Liste an unsere Liste von in Frage kommenden Sätzen anhängen\n",
    "            corpus_list.append(list)\n",
    "\n",
    "    # Seed sentence auswählen\n",
    "    seed_id, seed_sentence = choose_seed(target, corpus_list)\n",
    "\n",
    "    # Satz zum Bundle hinzufügen\n",
    "    bundle.append(seed_sentence)\n",
    "    # Diesen Satz aus corpus_list entfernen (denn wir wollen ja keinen Satz doppelt im Bundle haben)\n",
    "    corpus_list.remove(corpus_list[seed_id])\n",
    "\n",
    "    print(\"Generiere Distraktoren mit Fastsubs...\")\n",
    "    # Von Fastsubs distractors generieren lassen\n",
    "    distractor_list = fastsubs_distractor_generator(\n",
    "        fastsubs_instance, seed_sentence, target\n",
    "    )\n",
    "\n",
    "    print(\"...\")\n",
    "    print(\"Unser erster Satz:\")\n",
    "    print(\"'\" + \" \".join(seed_sentence) + \"'\")\n",
    "    print(\"Disambiguation level: \" + str(disamb(bundle, target, distractor_list)))\n",
    "\n",
    "    print(\"...\")\n",
    "    print(\"Jetzt fangen wir an, weitere Sätze zu suchen.\")\n",
    "    print(\"...\")\n",
    "\n",
    "    # Hier suchen wir mithilfe einer while-Schleife immer den nächsten Satz aus, der unser disambiguation level optimiert.\n",
    "    count = 1\n",
    "    while count < 4:\n",
    "        best_sentence_id = best_next_sentence(\n",
    "            corpus_list, bundle, target, distractor_list\n",
    "        )\n",
    "        if best_sentence_id != -1:\n",
    "            bundle.append(corpus_list[best_sentence_id])\n",
    "            corpus_list.remove(corpus_list[best_sentence_id])\n",
    "            print(\"Satz Nr. \" + str(count + 1) + \" gefunden!\")\n",
    "            print(\n",
    "                \"Disambiguation level: \" + str(disamb(bundle, target, distractor_list))\n",
    "            )\n",
    "        else:\n",
    "            bundle.append(\n",
    "                [\"ERROR: target_prob/max_other_prob = 0. Noch einmal versuchen?\"]\n",
    "            )\n",
    "            break\n",
    "        count = count + 1\n",
    "\n",
    "    # output\n",
    "    output(bundle, target)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    corpus = open(\n",
    "        \"data/incoming_text_data/sentences.txt\",\n",
    "        \"r\",\n",
    "    )\n",
    "    target = \"pears\"\n",
    "    main(corpus, target)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
